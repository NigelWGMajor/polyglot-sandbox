{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "Rationalizing the flow of data between different sources.\n",
    "\n",
    "Sources of streamed data include\n",
    "- strings\n",
    "- string collections\n",
    "- files\n",
    "- other streams (network, memory, blobs)\n",
    "there are also wrappers  which potentially contain, package or deliver deliver these, e.g.\n",
    "- folders\n",
    "- repositories\n",
    "- archives\n",
    "- crypto packages\n",
    "When we work with these, we might need to distinguish different content types:\n",
    "- binary\n",
    "- text\n",
    "- zipped\n",
    "- encrypted\n",
    "- json\n",
    "- xml\n",
    "- media\n",
    "There are thousands of content types in the web's content-type, and we clearly don't need to complicate things.\n",
    "<pre>\n",
    "Let's regard this as the use cases we need to accommodate, and see whether they fit together:\n",
    "\n",
    " File system --> Folder      --> File    \\                       /  File     --> Folder      --> File system       \n",
    "Blob Storage --> Folder      --> Blob     \\                     /   Blob     --> Folder      --> Blob Storage       \n",
    "     Network --> Resource    --> Stream    \\                   /    Stream   --> Resource    --> Network     \n",
    "    Internet --> url         --> Response   == Source / Sink ==     Response --> url         --> Internet      \n",
    "    Database --> Query       --> Response  /                   \\    Response --> Query       --> Database       \n",
    "                 Environment --> String   /                     \\   String   --> Environment      \n",
    "                 Memory      --> Object  /                       \\  Object   --> Memory                 \n",
    "                 Console     --> String /                         \\ String   --> Console     \n",
    "\n",
    "The potential inputs mirror the outputs so it might be more meaningful to layer this:\n",
    "\n",
    "     Folder     Folder                          \n",
    "      File       Blob      Network    Internet    Console   Database  Memory   Environment  \n",
    "        |          |          |           |          |         |        |          |   \n",
    "      ------------------------ stream -----------------------------    object-- string -----\n",
    "                                  |                                             |\n",
    "                                 ------------------------------------------------- \n",
    "                                                  Source / Target\n",
    "                                 -------------------------------------------------\n",
    "                                   |       |      |      |        |          |\n",
    "                                Binary   Text   Json    Xml    Zipped    Encrypted      \n",
    "                                                         unzip <--|          |\n",
    "                                                           zip -->|          |\n",
    "                                                                  decrypt <--| \n",
    "                                                                  encrypt -->|           |\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¤” Thoughts\n",
    "\n",
    "There would be great advantages to using a consistent interface to move streaming data between different locations with a minimum of handling. Clearly there are several commonalities among the elements above, including:\n",
    "\n",
    "- As sources, may be single or collections\n",
    "- Behave either as a stream or as a string\n",
    "- Are good async candidates (except memory resident strings)\n",
    "- Can be consumed as targets and delivered as sources without regard for the actual format\n",
    "- Can be converted between formats by operations that typically behave a streams\n",
    "- May be chunked arbitrarily in numerous ways, e.g. line breaks, packet sizes, buffer sizes, bytes \n",
    "- All support basic stream ops: seek & read (if can be read), write & clear (if can be written)\n",
    "- As targets, may be single or collections\n",
    "- In common use, may be passed through from stage to stage in asynchronous or synchronous streaming\n",
    "\n",
    "The class used as a source would need to be initialized in different ways depending on the source type, but could then present a uniform interface for read operations.\n",
    "The class being used as a target would likewise be initialized ahead of the data flow, and would use a consistent interface for drawing down the data. \n",
    "\n",
    "There is a definite use case for an instance being targeted by one step of a process, then being used by another step as a source. In the context of async streaming, this would point towards a single object being both a source and a target, BUT this violates the exclusive lock required by most persistance systems, so if this is ever a use case it should be achieved using asynchronous concurrent queues or a similar technology.\n",
    "\n",
    "For processing between states, we would need a receiver and a transmitter, and an operation to perform in transit. The interfaces for the first two are the same as those needed by the preceding lines. the operation could be completely generic using lambdas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like it could be consistent between the types we want to handle. The separation of the Source and Target has a problem though. Typically we would be using some objects as interim storage between stages in a process, and as such would want to read the data from something that we have written to without incurring the overhead of rebuilding the object parameters, maybe we can simply change mode. This would be feasible as long as the act of changing over does the necessary release of the underlying stream resources.\n",
    "\n",
    "The implicit law would be that the object should be connectable only as a source or as a target at any time, never both. This implies a further state of disconnected.\n",
    "\n",
    "This might be simpler:\n",
    "\n",
    "```mermaid\n",
    "classDiagram\n",
    "\n",
    "direction BT\n",
    "\n",
    "class IBin{\n",
    "  <<interface>>\n",
    "  Read()\n",
    "  Write()\n",
    "  Seek()\n",
    "  +Mode\n",
    "}\n",
    "\n",
    "IBin <|-- Bin\n",
    "IBin <|-- Mode\n",
    "\n",
    "IDisposable <|-- Bin\n",
    "\n",
    "class Bin{\n",
    "  <<abstract>>\n",
    "  Dispose()\n",
    "}\n",
    "class Mode {\n",
    "<<Enumeration>>\n",
    "    Disconnected,\n",
    "    Readable,\n",
    "    Writable\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "BlobBin --|> Bin\n",
    "DataBin --|> Bin\n",
    "FileBin --|> Bin\n",
    "StringBin --|> Bin\n",
    "EnvironmentBin --|> Bin\n",
    "NetworkBin --|> Bin\n",
    "InternetBin --|> Bin\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¡ Possibilities\n",
    "\n",
    "So what we need is an underlying Disposable Abstract class that has concrete versions for our desired source types, all of which implement the simple IBin interface to encapsulate Read/Write/Seek operations. Each can be in one of three state, connected for read or write, or not connected.\n",
    "\n",
    "It then becomes feasible to use a generic processor to operate between a reader and writer, with the consistent interface\n",
    "\n",
    "```mermaid\n",
    "classDiagram\n",
    "\n",
    "class IBinProcessor{\n",
    "    <<interface>>\n",
    "    Execute(source target) BinResult\n",
    "    Cancel()\n",
    "    GetProgress() BinResult\n",
    "    -sourceIBin\n",
    "    -targetIBin  \n",
    "    -BinMonitor[]\n",
    "}\n",
    "class BinProcessor{\n",
    "    <<virtual>>\n",
    "\n",
    "}\n",
    "\n",
    "BinProcessor --|> IBinProcessor\n",
    "BinProcessor o-- BinReport\n",
    "\n",
    "class BinReport{\n",
    "    +Status\n",
    "    +Info\n",
    "}\n",
    "\n",
    "class IBinMonitor{\n",
    "    <<interface>>\n",
    "    ReportStatus() BinReport\n",
    "}\n",
    "\n",
    "class BinMonitor{\n",
    "    -BinProcessor\n",
    "    -Digest\n",
    "}\n",
    "\n",
    "BinProcessor \"1\" o-- \"0-n\" BinMonitor\n",
    "BinMonitor --|> IBinMonitor\n",
    "```\n",
    "\n",
    "We would typically initialize an instance of the default operation Processor, but to accommodate more complex scenarios this class is virtual, allowing specialized operation Processors as needed for different situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš§ Constructive Implications\n",
    "\n",
    "As of now, it looks like the following is emerging as a solution:\n",
    "\n",
    "A **Bin** is a piece of state that can be pulled from or pushed to its persistent medium: blob, file, string, web, whatever.\n",
    "\n",
    "To do anything to a Bin we can use an **BinProcessor** which can read from one _Bin_ while writing to another, wrapping asynchronous and streaming operations internally. The inputs and output can also be multiple bins to allow fan-in and and fan-out.\n",
    "\n",
    "All _Bins_ and _BinProcessors_ communicate by interfaces so multiple variants can be defined with appropriate separation of their internals.\n",
    "\n",
    "The _BinProcessor_ returns an **BinReport** on completion, but this can also be read using **ReportProgress()** and cancelled, delayed, restarted by using **SetStatusl()**. _(The implementations may not do anything meaningful with cancel or progress calls, sending a light beam of information to Mars is neither cancellable in flight or assessable in its progress), but if we can send these messages_\n",
    "\n",
    "As an alternative to polling progress, the processor can also be given an **BinMonitor** to push notifications to.\n",
    "\n",
    "Noting that object-in-memory requiring serialization/deserializing process might require additional information, for example Type information, and some operations (for example decryption, zipping) might require information beyond these interface: this is no problem as the class structure allows for dedicated data-rich BinProcessors Bins. The pattern is one of using minimal interfaces for the interconnections and rich specialized objects as need. The BionMonitor also has access to the digest, which is information held from prior reports.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
