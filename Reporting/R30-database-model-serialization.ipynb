{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database SchemaModel Serialization\n",
    "\n",
    "This is the the sandbox for extending the database SchemaModel towards \n",
    "\n",
    "- Generating the base SchemaModel from a sql query \n",
    "  - [ref](../Sql/Discovery-pk-fk.sql)\n",
    "- easily inserting \n",
    "  - implied links\n",
    "  - Parameters/External links\n",
    "- deciding bast defaults for Sorters and Filters \n",
    "  - and do these need to be bytes rather than bools?\n",
    "- Devise a good generic SOLID solution for Special Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// import packages and live code classes\n",
    "// packages:\n",
    "#r \"nuget: Microsoft.Data.SqlClient\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// import composite containing all support classes ...\n",
    "\n",
    "#!import \"../code/composite.cs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Demo that the library is working\n",
    "\n",
    "open (or move to where you can see it) a browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// Quick demo to test library:\n",
    "// Load some existing Json:\n",
    "var json = FileData.FromFile(\"../.data/instances-raw.json\");\n",
    "// Generate a page from that:\n",
    "var page = Nest.RenderPageStepping(json,10,\"Hello Json-to-Html!\");\n",
    "// Push to a file and load into the browser:\n",
    "var htmlPath = \"../.html/Schema-page.html\";\n",
    "_ = FileData.ToFile(page, htmlPath);\n",
    "FileData.RunFile(htmlPath);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context for the SchemaModel\n",
    "\n",
    "The starting point for building a SchemaModel is to extract from the existing database (or perhaps a single schema)\n",
    "- The schema.table.column info\n",
    "- Primary Keys\n",
    "- Foreign Key\n",
    "\n",
    "We will extract this info as json using a sql query and deserialize into the base SchemaModel.\n",
    "\n",
    "(We want the SchemaModel to be json serializable for ease of storage and exchange)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// add sql kernel\n",
    "#r \"nuget:Microsoft.DotNet.Interactive.SqlServer,*-*\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#!powershell\n",
    "docker start awsql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "// import a connection string\n",
    "\n",
    "\n",
    "#!import ..\\.data\\connect-aw-db-dox.csx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "sql"
    },
    "polyglot_notebook": {
     "kernelName": "sql"
    }
   },
   "outputs": [],
   "source": [
    "#!sql-aw-db --name pkReferences\n",
    "--- \n",
    "select kcu2.table_schema + '.' + kcu2.table_name + '.' + kcu2.column_name as PrimaryKey\n",
    ", kcu1.table_schema + '.' + kcu1.table_name + '.' + kcu1.column_name as ForeignKey\n",
    "from information_schema.referential_constraints rc\n",
    "join information_schema.key_column_usage kcu1\n",
    "on kcu1.constraint_catalog = rc.constraint_catalog \n",
    "   and kcu1.constraint_schema = rc.constraint_schema\n",
    "   and kcu1.constraint_name = rc.constraint_name\n",
    "join information_schema.key_column_usage kcu2\n",
    "on kcu2.constraint_catalog = rc.unique_constraint_catalog \n",
    "   and kcu2.constraint_schema = rc.unique_constraint_schema\n",
    "   and kcu2.constraint_name = rc.unique_constraint_name\n",
    "   and kcu2.ordinal_position = kcu1.ordinal_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// pass the sql results to C#\n",
    "\n",
    "#!share --from sql-aw-db pkReferences\n",
    "\n",
    "pkReferences.Display();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So ...\n",
    "\n",
    "We have set up a system whereby we can interact with the sql and c# environments happily.\n",
    "this allows us to develop scripts and code in parallel in the same window.\n",
    "\n",
    "Some notes on the above:\n",
    "\n",
    "- Import packages in a cell that only imports libraries, otherwise the other code will try to run before the dependency has finished loading.\n",
    "- When it comes to importing code directly, I found that code which depends on other classes should be imported in the same file or you will get strange errors, even if the previous file contained the dependencies.\n",
    "- It is quite feasible to run the sql connection string by importing it, which means we don't have to make the credentials visible in this file\n",
    "- This environment can be Gitted, as long as the folders with a leading period are excluded in the gitignore file: this allows us to keep stuff private.\n",
    "- When rerunning sql, the kernel will tell you it is already connected: avoid this by only rerunning the latest queries\n",
    "- The #!sql... command should be the first line in the cell!\n",
    "- It is easy to pass the results to C# for serialization or whatever, as demonstrated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#!sql-aw-db --name allColumns\n",
    "--select * from information_schema.columns\n",
    "select table_schema + '.' + table_name + '.' + column_name as 'Identity',\n",
    "CASE IS_NULLABLE WHEN 'yes' Then 'true' ELSE 'false' END as IsNullable,\n",
    "DATA_TYPE as FieldDatatype\n",
    "from information_schema.columns\n",
    "select distinct data_type from information_schema.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// This needs to go into the Fields class for rationalization\n",
    "\n",
    "enum FieldDataTypes \n",
    "{\n",
    "    Bit,\n",
    "    Date,\n",
    "    Datetime,\n",
    "    Decimal,\n",
    "    Geography,\n",
    "    Hierarchyid,\n",
    "    Int,\n",
    "    Money,\n",
    "    Nchar,\n",
    "    Numeric,\n",
    "    Nvarchar,\n",
    "    Smallint,\n",
    "    Smallmoney,\n",
    "    Time,\n",
    "    Tinyint,\n",
    "    Uniqueidentifier,\n",
    "    Varbinary,\n",
    "    Varchar,\n",
    "    Xml\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#!sql-aw-db --name fieldDefinitions\n",
    "\n",
    "with c as (\n",
    "select \n",
    "table_schema SchemaName,\n",
    "table_name TableName,\n",
    "column_name FieldName,\n",
    "lower(table_schema + '.' + table_name + '.' + column_name) as 'identifier',\n",
    "CASE is_nullable WHEN 'yes' Then 'true' ELSE 'false' END as IsNullable,\n",
    "DATA_TYPE as FieldDatatype\n",
    "from information_schema.columns\n",
    "),\n",
    "k as\n",
    " (\n",
    "select \n",
    " lower(kcu2.table_schema + '.' + kcu2.table_name + '.' + kcu2.column_name) as Identifier\n",
    ", lower(kcu1.table_schema + '.' + kcu1.table_name + '.' + kcu1.column_name) as Reference\n",
    "from information_schema.referential_constraints rc\n",
    "join information_schema.key_column_usage kcu1\n",
    "on kcu1.constraint_catalog = rc.constraint_catalog \n",
    "   and kcu1.constraint_schema = rc.constraint_schema\n",
    "   and kcu1.constraint_name = rc.constraint_name\n",
    "join information_schema.key_column_usage kcu2\n",
    "on kcu2.constraint_catalog = rc.unique_constraint_catalog \n",
    "   and kcu2.constraint_schema = rc.unique_constraint_schema\n",
    "   and kcu2.constraint_name = rc.unique_constraint_name\n",
    "   and kcu2.ordinal_position = kcu1.ordinal_position\n",
    ") \n",
    "select top 5 \n",
    "c.Identifier, FieldName,TableName,SchemaName,IsNullable, FieldDatatype, Reference\n",
    " from c left join k on c.[identifier] = k.identifier\n",
    " -- where reference is not null\n",
    " for json path, include_null_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#!share --from sql-aw-db fieldDefinitions\n",
    "\n",
    "var k = fieldDefinitions;\n",
    "// The result is a array to accommodate potential multiple rowsets. \n",
    "// We could access the Data and Schema properties but extracting the json works fine!\n",
    "FileData.ToFile(k[0].ToJsonString().ToString(), \"../.data/fieldDefinitions00.json\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the notebook and the SSMS interface do a bunch of strange stuff with the results of a json query. We have already managed this awkwardness in our library, so let's use that instead.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var pw = Environment.GetEnvironmentVariable(\"AW_DB_DOX\");\n",
    "var cs = $\"Server=127.0.0.1,2433; User=sa; Password={pw}; Initial Catalog=AdventureWorks2022;trust server certificate=true\";\n",
    "var _sql = new JsonSqlClient(cs);\n",
    "\n",
    "var query = \n",
    "  \"with Data as (\"\n",
    "+ \"select  \"\n",
    "+ \"table_schema SchemaName, \"\n",
    "+ \"table_name TableName, \"\n",
    "+ \"column_name FieldName, \"\n",
    "+ \"lower(table_schema + '.' + table_name + '.' + column_name) as 'identifier', \"\n",
    "+ \"CASE is_nullable WHEN 'yes' Then 'true' ELSE 'false' END as IsNullable, \"\n",
    "+ \"DATA_TYPE as FieldDataType \"\n",
    "+ \"from information_schema.columns \"\n",
    "+ \"), \"\n",
    "+ \"k as \"\n",
    "+ \" ( \"\n",
    "+ \"select  \"\n",
    "+ \" lower(kcu2.table_schema + '.' + kcu2.table_name + '.' + kcu2.column_name) as Identifier \"\n",
    "+ \", lower(kcu1.table_schema + '.' + kcu1.table_name + '.' + kcu1.column_name) as Reference \"\n",
    "+ \"from information_schema.referential_constraints rc \"\n",
    "+ \"join information_schema.key_column_usage kcu1 \"\n",
    "+ \"on kcu1.constraint_catalog = rc.constraint_catalog  \"\n",
    "+ \"   and kcu1.constraint_schema = rc.constraint_schema \"\n",
    "+ \"   and kcu1.constraint_name = rc.constraint_name \"\n",
    "+ \"join information_schema.key_column_usage kcu2 \"\n",
    "+ \"on kcu2.constraint_catalog = rc.unique_constraint_catalog  \"\n",
    "+ \"   and kcu2.constraint_schema = rc.unique_constraint_schema \"\n",
    "+ \"   and kcu2.constraint_name = rc.unique_constraint_name \"\n",
    "+ \"   and kcu2.ordinal_position = kcu1.ordinal_position \"\n",
    "+ \")  \"\n",
    "+ \"select  \"\n",
    "+ \"data.Identifier, FieldName,TableName,SchemaName,IsNullable, FieldDataType, Reference \"\n",
    "+ \" from data left join k on data.[identifier] = k.identifier \"\n",
    "+ \" -- where reference is not null \"\n",
    "+ \" for json path, include_null_values \";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var x = _sql.JsonSingleUsingQuery(query);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "public class FieldInfo\n",
    "{\n",
    "    public string Identifier { get; set; }\n",
    "    public string FieldName { get; set; }\n",
    "    public string TableName { get; set; }\n",
    "    public string SchemaName { get; set; }\n",
    "    public string IsNullable   { get; set; }\n",
    "    public string IsExcluded {get; set; }\n",
    "    public string IsEnabled { get; set; }\n",
    "    public string FieldDataType { get; set; }\n",
    "    public string Reference { get; set; }\n",
    "    public override string ToString()\n",
    "      => $\"{SchemaName}.{TableName}.{FieldName}<{FieldDataType}>\";\n",
    "    public string PreProcess { get; set; }\n",
    "    public string PostProcess { get; set; }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var y = JsonSerializer.Deserialize<FieldInfo[]>(x);\n",
    "\n",
    "y.Count().Display();\n",
    "for (int ix = 50; ix < 54; ix++)\n",
    "y[ix].Display();\n",
    "foreach ( var f in y.Where(y => y.Reference.Length > 12))\n",
    "   f.Identifier.Display();\n",
    "foreach ( var f in y.Where(y => y.SchemaName == \"Sales\"))\n",
    "   f.TableName.Display();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to build the SchemaModel directly from the database query. This can be build into the SchemaModeling class.\n",
    "For efficiency, we could easily wrap the array in a dictionary (or multiple dictionaries) for speedy service: these would be generate from Linq queries of the SchemaModel vey easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process for building a SchemaModel\n",
    "\n",
    "! - GenerateModel(database)\n",
    "    This makes the full field list and imports all key references.\n",
    "\n",
    "    Exclude(*.*.*) schema, table or field wildcards\n",
    "    Include(*.*.*)\n",
    "\n",
    "    AddImpliedReference\n",
    "    AddParameter\n",
    "\n",
    "If something is excluded, any references to it will generate a variable.\n",
    "If it is not enabled, it is effectively ignored completely\n",
    "\n",
    "Once we have done this, we have the operational data SchemaModel and have defined the scope of our queries.\n",
    "\n",
    "Some fields have composite content.\n",
    "Where this is the case, we might have to preprocess the data, for example\n",
    "- decompress\n",
    "- decrypt\n",
    "- redact\n",
    "- look up\n",
    "\n",
    "\n",
    "The data might also result in additional information structure, for example a json-encapsulated value could expand into a subtree. At this point the presentation schema departs from the storage schema\n",
    "\n",
    "PostProcessing would occur as the last step, typically to format, truncate or simplify the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Process of ingesting a schema into this SchemaModel.\n",
    "\n",
    "Using the database, we initialize a SchemaModel in a single pass, which gets all field definitions across all schemas. PK-FK relationships are detected.\n",
    "\n",
    "(The SchemaModel is from this point on serializable as json. Because the fields are stored in an array, they can be iterated through using Linq.)\n",
    "\n",
    "### Schema and Scope\n",
    "\n",
    "Schemas never intended to be used can be stripped before the SchemaModel is saved. \n",
    "\n",
    "As an alternative to removing unwanted schemas, we an simply add exclusions to get focused on our main area of interest.\n",
    "\n",
    "### References\n",
    "\n",
    "References which are excluded (or not found) automatically become available as external parameters.\n",
    "\n",
    "We can also add implied references and parameters. We will use this SchemaModel to generate design-time queries and sub-models to use at run-time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Query Generation\n",
    "\n",
    "The current query generator simply takes the Links provided and generates Sql (by deciding whether the links are peers or nestings) and returns the query, along with a text output describing the way the links were resolved (for diagnostic purposes during development  mainly).\n",
    "In our case we have way more information than just the links already.\n",
    "\n",
    "The current process for generating the sql involves \n",
    "- an arbitrary list of links is passed into the GenerateNestedQuery method.\n",
    "- this calls into the ProcessMutliLinkQuery method with recursion.\n",
    "  - The series is started with an empty output array and a list of links.\n",
    "    - initially:\n",
    "      - the first link is made current\n",
    "      - it is added as root\n",
    "      - t is removed from the list\n",
    "      - we recurse.\n",
    "    - therafter\n",
    "      - Each successive link is evaluated and we determine whether it should be added as a peer or added as a nest.\n",
    "      - we either add as nest or add as a peer.\n",
    "    - The Add As Root, Add as  Nest and Add As Peer calls are themselves recursive:\n",
    "      - They are very similar in that they dynamically get the column names.\n",
    "      - ***It is feasible to use the GetColumnNames call to question the SchemaModel and inject any controls there!***\n",
    "\n",
    "Example select statements:\n",
    "Select \n",
    "    Name, City from Addresses\n",
    "    `'<!pre!redact!>' + Name` as Name, City\n",
    "    `'<!pre!decrypt!!post!hash!>' + Name` as name, City\n",
    "\n",
    "In this way the data returned from the database can be tagged for special handling by the postprocessor later (when it prepared for rendering).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**CHALLENGE**\n",
    "\n",
    "When the preprocess results in an expansion, we cannot do that until we have the data resulting from the query. When we do that, we will need to intercept the value when the nest ios being made, and process accordingly.\n",
    "this needs to be looked at in the Nest routine that generates the html.\n",
    "\n",
    "This occurs in `AsHtmlStepping` which builds a start and end html string, returning the two together.\n",
    "This is totally recursive, and has different handlers based on the type of Nesting\n",
    "- Item\n",
    "- list\n",
    "- SetList\n",
    "- Set\n",
    "\n",
    "A strategy for dealing with this might be\n",
    "- The Pre and Post clearly live in the Values.\n",
    "- If Nest contains a pre/post, this can be detected at the moment the nest enters the AsHtmlStepping method. the handler can process the nest, and return the nest in its modified form!\n",
    "- it then passes into the Nesting switch and we are DONE.\n",
    "- the Processors are really the same whether post or pre!A processor could be defined with \n",
    "  - the activating Token\n",
    "  - a chain of lambdas for the process chain\n",
    "- The Nest would call the Lambda processor and return the modified Nest.\n",
    "- the recursion should take care of the children just fine.\n",
    "\n",
    "**Implies: we insert the detection at the start of the html process before the Nesting branch and pass to a handler to process based in the token and the content!**\n",
    "\n",
    "We can define the query scope by explicitly choosing the links to traverse, \n",
    "or define a start and end table and have the system generate the possible paths from the known links. \n",
    "\n",
    "Perhaps as an interim, if we have a link follower, we cold get a list of potential tables, from which we could exclude.\n",
    "\n",
    "Either way, we have a query that will harvest the data, inject the appropriate column data for pre and post processing.\n",
    "\n",
    "When we run the query, it generates json, which is storable.\n",
    "\n",
    "The schema and data are in the form of Json.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Further thoughts:\n",
    "\n",
    "What we need to achieve:\n",
    "- Retrieve meaningful data including relationships\n",
    "- Decode, extract and redact some of that data to allow it to be used more freely\n",
    "- The ability to save, compare and view this data offline  \n",
    "\n",
    "How we provision this:\n",
    "- At Design-time, we SchemaModel the data schema\n",
    "  - Manual steps are required only for defining special behavior, the rest is reflected.\n",
    "- At run-time\n",
    "  - Parameters (or limits) are provided\n",
    "  - The system builds and executes the sql\n",
    "  - Results are returned as json\n",
    "  - The system post-processes the data for expansion, redaction, whatever is required.\n",
    "  - The output of this is Html, which can be viewed, stored, shared and reviewed offline.\n",
    "\n",
    "Assuming a process where \n",
    "\n",
    "- ** At Design Time**\n",
    "  - a SchemaModel has been set up for a particular function \n",
    "  - or a previously saved SchemaModel is loaded\n",
    "  - available parameters/filters are defined\n",
    "\n",
    "- ** At run time\n",
    "  - The sql is generated using the SchemaModel and any supplied parameters/filters\n",
    "  - The generated sql aliases the column names with a key containing the field indexes. \n",
    "  - The values are received back from the query as json serialized objects.\n",
    "\n",
    "  When we process the data that comes back:\n",
    "  - We use the index to retrieve the field metadata\n",
    "  - Pre- and post- processing can be applied where indicated by the field metadata data\n",
    "  - We intercept right at the point where the html generator is about to determine the structure\n",
    "  - This allows us to inject or remove structured data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## The main Generator process\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "subgraph Context\n",
    "u(((user))) \n",
    "u --> g0\n",
    "db[(Database)]\n",
    "js(JsonSql)\n",
    "fb{{FileBin>}}\n",
    "subgraph Generator\n",
    "g0[[Get Context]]\n",
    "g0 --> g1[[Retrieve SchemaModel]]\n",
    "g1 -->g2[[Inject Filters]]\n",
    "g2 --> g3[[Generate Query]]\n",
    "g3 --> g4[[Submit Query]]\n",
    "jr[/JsonResults/]\n",
    "jr --> g5[[PostProcess results into Nest]]\n",
    "g5 --> g6[[Persist Nest]]\n",
    "g6 --> g7[[Convert Nest to Html]]\n",
    "m[/SchemaModel/]\n",
    "end\n",
    "g1 --> m\n",
    "m --> g3\n",
    "m --> g5\n",
    "g1 <-.-> fb\n",
    "g6 <-.-> fb\n",
    "g4 --> js\n",
    "js --> db\n",
    "db --> js\n",
    "js --> jr\n",
    "g7 --> u\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As of now ...\n",
    "\n",
    "The process seems sound, but the libraries might need some refactoring and renaming.\n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "- JsonSql \n",
    "  - allows JsonSqlClient\n",
    "  - gets sql to the db and returns json.\n",
    "- FileData (migrating to FileBin...?) \n",
    "  - supports various simple file operations\n",
    "- Nest\n",
    "  - Manages hierarchial data\n",
    "  - Generates Css, Js and Html, and full pages from json data\n",
    "  - Generates Sql from a list of links\n",
    "\n",
    "The Nest seems to be a little confused, it should probably break away\n",
    "\n",
    "- Nest\n",
    "  - Manage hierachical Data\n",
    "  - Generate Nest from json data\n",
    "- QueryGenerator\n",
    "  - Generate sql queries from a ~~nest~~ SchemaModel\n",
    "  - (could do other queries in the same way!)\n",
    "- Html Generator\n",
    "  - Generate Html frp, a nest\n",
    "At the moment the Nest does too much because it is responsible fopr both generating the prequery and converting the post query data.\n",
    "It was also doing too little because we need to Postprocess the data before convertying to html.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## SchemaModel-generator - Sql-generator - Json-translator - View-Generator\n",
    "\n",
    "Splitting the process into atomic operations (<u>S</u>-olid)\n",
    "\n",
    "Design-time:\n",
    "- SchemaModel Generation queries the database to produce a base SchemaModel\n",
    "- SchemaModel Refinement modifies the SchemaModel for a specific purpose\n",
    "\n",
    "Run-time: \n",
    "- Sql Generator combines a SchemaModel with run-time filters to produce a sql query\n",
    "- A JsonSql handler executes the query and returns SchemaModel-indexed json\n",
    "- A PostProcessor uses the SchemaModel to reconstitute the json data\n",
    "- A View Generator converts the json to a viewable html page or panel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes for minimal iterability\n",
    "\n",
    "```Mermaid\n",
    "classDiagram\n",
    "class SchemaModeler{\n",
    "    Generate(database) \n",
    "    Refine(qualifications)\n",
    "    Save()\n",
    "    Load()\n",
    "    PostProcess(SchemaModel) : json\n",
    "}\n",
    "class QueryGenerator{\n",
    "    GenerateQuery(model, filters) : query\n",
    "}\n",
    "class JsonSql{\n",
    "    JsonFromSingleQuery(query) : json\n",
    "}\n",
    "class PageProducer{\n",
    "    MakePage(json, options) : html\n",
    "}\n",
    "class FileBin {\n",
    "    Save()\n",
    "    Load()\n",
    "    Launch()\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clearer version \n",
    "\n",
    "The SchemaModeler produces (and modifies) a SchemaModel representing the Database Schema.\n",
    "The QueryGenerator uses a (possibly modified) SchemaModel and optional filters to generate and execute a query to retrieve data using the SchemaModel, in Json format.\n",
    "The NestedDataModeler uses the SchemaModel to post-process the raw results, converting these to a serializable hierarchical data structure (Nested Data) including both information and the hierarchical data structure. \n",
    "The NestedDataPresenter accepts the NestedData and converts this to a displayable form using html, css and javascript.\n",
    "```mermaid\n",
    "classDiagram \n",
    "Direction LR\n",
    "\n",
    "\n",
    "ISchemaModeler <|-- SqlSchemaModeler\n",
    "SqlSchemaModeler  *-- SqlJsonClient\n",
    "SqlJsonClient *-- SqlDataSource\n",
    "SqlSchemaModeler *-- SchemaModel\n",
    "SchemaModel *-- BaseFields\n",
    "SchemaModel *-- Overlays\n",
    "SchemaModel ..|> SchemaModelFile\n",
    "ModelFile ..|> SchemaModel\n",
    "\n",
    "IModelQuery <|-- SqlModelQuery\n",
    "SqlModelQuery *-- Filters\n",
    "Filters ..> SchemaModel\n",
    "SqlModelQuery *-- SchemaModel\n",
    "SqlModelQuery --|> QueryResult\n",
    "SqlModelQuery ..> SqlJsonClient\n",
    "\n",
    "SqlModelQuery ..|> NestedDataModeler\n",
    "\n",
    "INestedDataModeler <|-- NestedDataModeler\n",
    "NestedDataModeler *-- SchemaModel\n",
    "NestedDataModeler *-- QueryResult\n",
    "NestedDataModeler ..|> NestedData\n",
    "NestedData ..|> NestedDataFile\n",
    "NestedDataFile ..|> NestedData\n",
    "\n",
    "NestedDataPresenter <|-- NestedDataPresenter\n",
    "NestedDataPresenter *-- NestedData\n",
    "NestedDataPresenter ..|> Page\n",
    "\n",
    "class ISchemaModeler {\n",
    "    <<interface>>\n",
    "    ctor(jsonSql)\n",
    "    Initialize()\n",
    "    Refresh()\n",
    "    Overlay()\n",
    "    Save()\n",
    "    Load()\n",
    "    Prune()\n",
    "}\n",
    "class IModelQuery{\n",
    "    <<interface>>\n",
    "    ctor(jsonsql, SchemaModel)\n",
    "    GetFilters()\n",
    "    Execute(filters)\n",
    "    ExecuteData(path, filters)\n",
    "    ExecutePage(path, filters)\n",
    "}\n",
    "class INestedDataModeler{\n",
    "    <<interface>>\n",
    "    SchemaModel()\n",
    "}\n",
    "class NestedDataPresenter{\n",
    "    <<interface>>\n",
    "    +PresentationStyle\n",
    "    +Options\n",
    "    GetPage(options)\n",
    "\n",
    "}\n",
    "class SchemaModelFile{\n",
    "    <<json>>\n",
    "}\n",
    "class QueryResult{\n",
    "    <<json>>\n",
    "}\n",
    "class NestedData{\n",
    "    <<json>>\n",
    "}\n",
    "class NestedDataFile{\n",
    "    <<json>>\n",
    "}\n",
    "class Page{\n",
    "    <<html+css>>\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence\n",
    "\n",
    "```mermaid\n",
    "sequenceDiagram\n",
    "Actor d as Designer\n",
    "participant dm as ISchemaModeler\n",
    "participant mq as IModelQuery\n",
    "participant rm as INestedDataModeler\n",
    "participant pp as NestedDataPresenter\n",
    "participant fs as File System\n",
    "participant mm as SchemaModel\n",
    "participant js as JsonSqlClient\n",
    "participant QH as Query Handler\n",
    "Actor u as User\n",
    "\n",
    "d ->> dm : Initialize()\n",
    "dm -->> mm : Base SchemaModel\n",
    "alt\n",
    "d ->> dm : Save()\n",
    "dm -->> fs : <model>\n",
    "end\n",
    "alt\n",
    "d ->> dm : Load()\n",
    "fs -->> dm : <model>\n",
    "end\n",
    "d ->> dm : Overlay()\n",
    "u ->> QH : Execute(Query, filters)\n",
    "QH ->> mq : Init(query)\n",
    "QH ->> mq : Execute(filters)\n",
    "mq ->> mm : Get\n",
    "mq ->> js : <query>\n",
    "mq ->> rm : SchemaModel(queryResult)\n",
    "alt\n",
    "rm -->> fs : <nested data>\n",
    "end\n",
    "rm ->> pp: GetPage()\n",
    "pp -->> rm : <page>\n",
    "rm -->> u : <page>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designer Initializes a Data SchemaModel\n",
    "The connection string to the database is injected into a JsonSqlClient.\n",
    "The JsonSqlClient is then in injected into an IDataModeler instance.\n",
    "Then,\n",
    "- Initialize() can generate the base SchemaModel\n",
    "- Overlay() can customize the SchemaModel\n",
    "- Refresh() can update the base SchemaModel under the overlays\n",
    "- Save() and Load() can persist the SchemaModel\n",
    "- Prune() can make a pruned version of the SchemaModel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executes a query \n",
    "\n",
    "To execute a query (for later publication), \n",
    "- The IModelQuery must be instantiated with the JsonSql source and the applicable SchemaModel\n",
    "- The Execute function can be called with or without filters.\n",
    "- The resulting QueryResult is passed into an instance of the NestedDataModeler\n",
    "- The result is storable NestedData\n",
    "- It would be possible to inject a NestedDataPresenter into the constructor too and generate the page immediately.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish Nested Data\n",
    "\n",
    "To publish nested data, \n",
    "- Instantiate an NestedDataPresenter with appropriate options \n",
    "- Either call GetPage, or assemble your page using the other calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UI Connection issues\n",
    "\n",
    "There may be a need for some kind of Query Manager to\n",
    "- Locate the correct SchemaModel\n",
    "- Connect the correct DataSource to the DataModeller\n",
    "- Offer the correct Filters to the UI\n",
    "- Optionally configure a NestedDataPresenter\n",
    "- Pass the SchemaModel and Data Client and optionally the NestedDataPresenter to the SchemaModelQuery\n",
    "- Persist the Nested Data and/or the Page or both\n",
    "\n",
    "Generally, there might be a need to configure how and when various intermediary products are persisted, temporarily of permanently.\n",
    "\n",
    "Always persist or stream:\n",
    "- SchemaModels\n",
    "- Pages\n",
    "Likely persist for reuse in a diagnostic situation:\n",
    "- NestedData\n",
    "Preferably throw away:\n",
    "- QueryResult\n",
    "\n",
    "There are not many variants of this, perhaps we could control this with a single PersistanceFlags enum.\n",
    "\n",
    "Also, viewing this as a Data Pipeline, it is an excellent candidate for Flow Management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New thoughts (random)\n",
    "\n",
    "- The field defs could have a Class which could be transmitted to the UI! Or we could generate on e based on a property.\n",
    "- The fields could have an importance which could translate to a class on the FE and also be used to generate a prioritized potential-for-filter candidate list.\n",
    "- There is not much overhead in saving the index/field-code in the field...probably less than using a dictionary.\n",
    "- It might be useful to auto-limit the initial SchemaModel build by schema(s)\n",
    "- Using the concept of a base SchemaModel and overlays, for this to idempotent (so that the base can be refreshed) we need to use an open-closed principle in that the base data should not be changed by the overlays directly.\n",
    "  - This means that everything potentially applied may modify the interpreted result but never affects the base properties, \n",
    "    - identity\n",
    "    - data type\n",
    "    - schema/table/column\n",
    "  - but allows run-time variants to persist\n",
    "    - disabling\n",
    "    - exclusion\n",
    "    - internal and external parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOLID revisited\n",
    "\n",
    "- Single responsibility: Not only that, but we need to embrace the idea that an operation comes into existence for a single atomic purpose, awakes some state and finally deposits the results. This should be sufficient for future operations to act appropriately.\n",
    "- Open-Closed: When we are building state from sequential operations, we should consider this to be a base operation with overlaid operations, where the original can be repeated without corrupting the overlaid state, to allow out-of-scope evolution to be incorporated.\n",
    "- Liskov: The interfaces required for the structural organization of effort should be as simple as possible to allow switching providers with minimal complexity and no alteration of flow\n",
    "- Interfaces: These should be structural in nature, defining the way things are assembled and flow. The generic portions are allow diverse operations to mesh cleanly.\n",
    "- Dependencies: We need dependencies to bubble up to a layer where they can be easily inherited or injected at runtime. This is also critical for data privacy and security.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components\n",
    "\n",
    "### JsonSqlClient\n",
    "```mermaid\n",
    "flowchart LR\n",
    "cs[/Connection String/] -.-> jc[[JsonSqlClient]]\n",
    "q[[JsonSingleUsingQuery]] --> jc\n",
    "jc -.-> j(json)\n",
    "db[(Database)] -.-> jc\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### SchemaModeler\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "subgraph input\n",
    "cs[/Connection String/] \n",
    "end\n",
    "cs -.-> dm[[SchemaModeler]]\n",
    "i[[Initialize]] --> dm\n",
    "r[[Refresh]] --> dm\n",
    "p[[Prune]] --> dm\n",
    "o[[Overlay]] --data--> dm\n",
    "s[[Save]] --path--> dm\n",
    "l[[Load]] --path--> dm\n",
    "dm <-.-> f\n",
    "subgraph output\n",
    "f(SchemaModel File)\n",
    "end\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SchemaModelQuery + NestedDataModeler\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "subgraph input\n",
    "cs[/Connection String/] \n",
    "m[/SchemaModel/] \n",
    "end\n",
    "m -.-> mq\n",
    "cs -.-> mq[[SchemaModelQuery]] \n",
    "mq -.-> mr[/ModelResults/] \n",
    "mr -.-> rm[[NestedDataModeler]]\n",
    "m -.-> rm\n",
    "gf -.-> m\n",
    "x[[Execute]] --filters--> mq\n",
    "\n",
    "gf[[GetFilters]] --> mq\n",
    "rm -.-> nd\n",
    "subgraph output\n",
    "nd(NestedData)\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NestedDataPresenter\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "subgraph input\n",
    "o[/Options/] \n",
    "nd(NestedData)\n",
    "end\n",
    "nd -.-> p[[NestedDataPresenter]]\n",
    "o -.-> p[[NestedDataPresenter]]\n",
    "pp[[GetPage]] --> p\n",
    "subgraph output\n",
    "h(html+css)\n",
    "end\n",
    "p -.-> h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "dm[DataModeler]\n",
    "js{{JsonSql}}\n",
    "mq[ModelQuery] \n",
    "rm[NestedDataModeler]\n",
    "pp[NestedDataPresenter]\n",
    "nd{{NestedData}}\n",
    "fd{{FileData}}\n",
    "mm{{Model}}\n",
    "\n",
    "fm{{Coordinator}}\n",
    "mq -.->|T| fm\n",
    "rm -.->|T| fm\n",
    "pp -.->|T| fm\n",
    "\n",
    "dm -.-> js\n",
    "dm -.-> mm\n",
    "mq -.-> js\n",
    "mq -.-> mm\n",
    "rm -.-> nd\n",
    "rm -.-> mm\n",
    "pp -.-> nd\n",
    "dm -.-> fd \n",
    "mq -.-> fd\n",
    "rm -.-> fd\n",
    "pp -.-> fd\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinator\n",
    "\n",
    "The tasks managed by the main classes can be simplified by a dedicated coordinator.\n",
    "To allow this, each must support a generic function that can be used to chain activity one to another. This is possible because the input and output types are predictable.\n",
    "\n",
    "An outside class can call the coordinator with instances of the classes, and any parameters required in addition to those cascaded\n",
    "\n",
    "e.g. `Coordinate([myModelQuery, myNestedDataModeler, MyNestedDataPresenter], connectionString, SchemaModel, PublicationOptions)` which will result in a call to\n",
    "\n",
    "`myModelQuery(connection, SchemaModel)` passing its output to \n",
    "`myNestedDataModeler()` which would pass its result to \n",
    "`myNestedDataPresenter(options)` which would ultimately return its result to the calling class.\n",
    "\n",
    "The parameters array would be consumed by the Process call as required by the participants.\n",
    "The whole coordinated process should occur asynchronously and should return a CoordinatedResult which can allow for and encapsulate errors.\n",
    "Passing a CoordinatedInput of T allows the receiver to access and consume parameters;\n",
    "Returning a CoordinatedOutput of T allows management of flow and errors and possibly cancellation or status\n",
    "\n",
    "Why do this?\n",
    "Because it limits interdependency between chained operations making them simpler and more single-minded.\n",
    "\n",
    "## ICoordinator - ICoordinated\n",
    "\n",
    "```mermaid\n",
    "classDiagram\n",
    "class ICoordinated{\n",
    "    <<interface>>\n",
    "    Process (CoordinatedInput<T>)  CoordinatedOutput<T>\n",
    "}\n",
    "class ICoordinator{\n",
    "<<interface>>\n",
    "    Coordinate(ICoordinated[], param [])\n",
    "\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "Any Coordinator-derived class can provide entry points to chain any kind of coordinated activities. Because the type can be defined to match the provider's requirements, the actual coordinator class is independent of its users, although the derived class can use (or overide) the abstract base class implementation. The coordinator is of course a thinly-veiled minimal implementation of a Flow Manager capable of pessimistic flow control."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     },
     {
      "aliases": [],
      "languageName": "T-SQL",
      "name": "sql-aw-db"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
